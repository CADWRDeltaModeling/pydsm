{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading hydro hdf5 files from DSM2\n",
    "\n",
    "This notebook is an example of using pydsm to read DSM2 h5 output.\n",
    "\n",
    "The timeseries are loaded as pandas DataFrame with datetime index and mcolumns of variable type (e.g. flow, stage, ec). This is similar to pyhecdss read in objects.\n",
    "\n",
    "In addition to the state of the model as time series, the HDF file also contains the input tables as intepreted by DSM2. I say interpreted because it also has important tables such as virtual cross-sections that is the geometry finally used by DSM2 even though the user specifies the physical geometry in the input files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pydsm.io\n",
    "#%conda install matplotlib\n",
    "# Turn on ones below if in debug or development mode\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening a H5 file\n",
    "This provides the handle to the HDF5 file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='../../tests/historical_v82.h5'\n",
    "h5f=h5py.File(filename,'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading H5 file with \n",
    "\n",
    "A HDF5 file consists of Groups and Datasets. \n",
    "Groups are like dicts with keys and values and Datasets are like arrays with some slicing abilities.\n",
    "\n",
    "A HDF5 file has a concept of path, similar to the file path.\n",
    "For example, the top level of the hydro h5 (HDF) file has 'hydro' as the top most Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Topmost group of hydro h5 file: \\n',list(h5f.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Children of hydro group:\\n',list(h5f.get('hydro').keys()))\n",
    "print('DSM2 Input Tables are children of input:\\n',list(h5f.get('hydro').get('input').keys()))\n",
    "print('DSM2 geometry are children of geometry: \\n', list(h5f.get('hydro').get('geometry').keys()))\n",
    "print('DSM2 time series output of state are children of data: \\n', list(h5f.get('hydro').get('data').keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf=h5f.get('hydro').get('input').get('boundary_flow')\n",
    "pd.DataFrame(bf[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tables=pydsm.io.list_groups_as_df(filename, '/hydro/input')\n",
    "for table in input_tables[0]:\n",
    "    path='/hydro/input/'+str(table)\n",
    "    print(path)\n",
    "    display(pydsm.io.read_table_as_df(filename, path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(h5f.get('/input'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hydro data file structure\n",
    "DSM2 Hydro HDF5 stores data under three groups:\n",
    " * /hydro/data\n",
    " * /hydro/input\n",
    " * /hydro/geometry\n",
    " \n",
    "The next cell prints out the tables available under each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_paths=['/hydro/input','/hydro/data','/hydro/geometry']\n",
    "for path in group_paths:\n",
    "    print(path)\n",
    "    for key in h5f.get(path).keys():\n",
    "        print('    ',key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channel indices to numbers\n",
    "The data in DataSets under /hydro/data is typically indexed by time, channel index, upstream/downstream if needed\n",
    "The channel index can be mapped to the channel number by looking up that information from /hydro/geometry/channel_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_numbers=pd.DataFrame(h5f.get('/hydro/geometry/channel_number')[:])\n",
    "print(channel_numbers)\n",
    "channel_index2number=channel_numbers[0].to_dict()\n",
    "index=157\n",
    "print('This channel number for index:',index, ' should be 169. It is ',channel_index2number[index])\n",
    "channel_number2index= {value: key for key, value in channel_index2number.items()}\n",
    "print('This channel index for number:', 169, ' should be ',index,'. It is ',channel_number2index[169])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_location=pd.DataFrame(h5f.get('/hydro/geometry/channel_location')[:],dtype=np.str)\n",
    "display(channel_location)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting time series data\n",
    "Extracting data can then be done using the channel numbers. All data arrays have the first axis as time. The time start and time interval is available in the attrs along with other meta data.\n",
    "\n",
    "Flow data shape is *time* x *channel index* x *channel location*\n",
    "\n",
    "time start is available in attribue \"START_TIME\"\n",
    "channel index to channel numbers is explained above\n",
    "channel location (upstream/downstream) is available in /hydro/geometry/channel_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_location[0].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flowdata = h5f.get('/hydro/data/channel flow')\n",
    "print(flowdata.shape)\n",
    "#\n",
    "interval_string=flowdata.attrs['interval'][0].decode('UTF-8')\n",
    "model=flowdata.attrs['model'][0].decode('UTF-8')\n",
    "model_version=flowdata.attrs['model_version'][0].decode('UTF-8')\n",
    "start_time=pd.to_datetime(flowdata.attrs['start_time'][0].decode('UTF-8'))\n",
    "print('Start time: ',start_time)\n",
    "print('time interval: ',interval_string)\n",
    "print('Model: ',model)\n",
    "print('Model Version: ',model_version)\n",
    "#\n",
    "print('Slicing along time for channel number: 441')\n",
    "channel_id=441\n",
    "location='UPSTREAM'\n",
    "channel_index= channel_number2index[channel_id]# channel_numbers[channel_numbers[0]==441] #-- slow way\n",
    "location_index=channel_location[channel_location[0].str.upper()==location]\n",
    "darr=flowdata[:,channel_index,location_index]\n",
    "ts441=pd.DataFrame(darr,\n",
    "                   columns=[str(channel_id)+'-'+location],\n",
    "                   index=pd.date_range(start_time,freq='30T',periods=darr.shape[0]),dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts441['01jan1990':'10jan1990'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in flowdata.attrs.keys(): print (key, flowdata.attrs[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydsm.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame()\n",
    "pd.DataFrame(h5f['/hydro/input/boundary_flow'][:],dtype=np.str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydsm.io\n",
    "x=pydsm.io.read_table_as_df(filename,'/hydro/input/boundary_flow')\n",
    "display(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb=pydsm.io.read_table_as_df(filename,'/hydro/geometry/channel_bottom')\n",
    "display(cb)\n",
    "print('Channel Bottom for Channel Number: ',441)\n",
    "print(cb[channel_number2index[441]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f5=h5py.File(filename,'r')\n",
    "catable=f5['/hydro/data/channel area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pydsm.io.read_table_attr(filename,'/hydro/data/channel area' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_metadata=pydsm.io.read_table_attr(filename,'/hydro/data/channel area')\n",
    "display(table_metadata)\n",
    "pd.to_timedelta(str(table_metadata['interval'].astype(str)[0]))\n",
    "pd.to_datetime(table_metadata['start_time'].astype(str)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TableMetaData:\n",
    "    pass\n",
    "tmd=TableMetaData()\n",
    "tmd.table_name='/hydro/data/channel area'\n",
    "tmd.interval=pd.to_timedelta('30min')\n",
    "tmd.start_time=pd.to_datetime('1990-01-02 00:00:00')\n",
    "tmd.dimension_labels=table_metadata['DIMENSION_LABELS'].astype('str')\n",
    "from ast import literal_eval as make_tuple\n",
    "tmd.shape=make_tuple(table_metadata['shape'])\n",
    "print(tmd.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=pydsm.io._convert_time_to_table_slice(\"01jan1980\",\"01jan1991\",tmd.interval,tmd.start_time,tmd.shape[0])\n",
    "print(s)\n",
    "x=catable[s,[501,502],0]\n",
    "#pydsm.io.read_table_as_df(filename,\"/hydro/data/channel area\",s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf=pd.DataFrame(data=np.array(x), index=pd.DatetimeIndex(data=pd.date_range(start=tmd.start_time+tmd.interval,freq=tmd.interval,periods=s.stop)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pydsm.io.read_table_as_df(filename,'/hydro/geometry/external_flow_names'))\n",
    "display(pydsm.io.read_table_as_df(filename,'/hydro/geometry/hydro_comp_point'))\n",
    "display(pydsm.io.read_table_as_df(filename,'/hydro/geometry/node_flow_connections'))\n",
    "display(pydsm.io.read_table_as_df(filename,'/hydro/geometry/qext'))\n",
    "display(pydsm.io.read_table_as_df(filename,'/hydro/geometry/reservoir_flow_connections'))\n",
    "display(pydsm.io.read_table_as_df(filename,'/hydro/geometry/reservoir_names'))\n",
    "display(pydsm.io.read_table_as_df(filename,'/hydro/geometry/reservoir_node_connect'))\n",
    "display(pydsm.io.read_table_as_df(filename,'/hydro/geometry/stage_boundaries'))\n",
    "display(pydsm.io.read_table_as_df(filename,'/hydro/geometry/transfer_names'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(h5f.get('/hydro/geometry/channel_location'),dtype=np.str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [15, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydsm.hydroh5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hydroh5=pydsm.hydroh5.HydroH5(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow4up=hydroh5.get_channel_flow('4','upstream')\n",
    "flow8down=hydroh5.get_channel_flow('8','downstream')\n",
    "ax1=flow4up.plot()\n",
    "flow8down.plot(ax=ax1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area4up=hydroh5.get_channel_area('4','upstream')\n",
    "area8down=hydroh5.get_channel_area('8','downstream')\n",
    "ax1=area4up.plot()\n",
    "area8down.plot(ax=ax1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vel4up=(flow4up/area4up)\n",
    "vel8down=(flow8down/area8down)\n",
    "ax1=vel4up.plot()\n",
    "vel8down.plot(ax=ax1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vel4up.index.freqstr"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('dev_pydsm': conda)",
   "language": "python",
   "name": "python37664bitdevpydsmcondab1c3bd5d933c4dabb1711f6f5582ad21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
