{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Total Inflow and Outflow from DSM2 Hydro setup\n",
    "\n",
    "The hydrodynamic model takes a number of flows as input that are specified in the input files. This notebook shows how one can calculate the total inflow from the boundary and source/sink terms. This is an important overall measure of the driving force in the model\n",
    "\n",
    "All the inflow, in the Sacramento-San Joaquin Delta, ultimately makes it out to the bay and the model has channel 441 which represents the entry to Carquinez Strait from the Delta. This notebook shows how to retrieve this data from the model output (HDF5 format) and compares it to the inflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydsm\n",
    "from pydsm.input import parser\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "import logging\n",
    "import pyhecdss\n",
    "pyhecdss.set_message_level(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Open the input files and read input into pandas DataFrame(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsm2_dir='d:/delta/dsm2_studies_master/studies/historical'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname=f'{dsm2_dir}/output/hydro_echo_hist_v2022_01.inp'\n",
    "with open(fname, 'r') as file:\n",
    "    tables = parser.parse(file.read())\n",
    "#Tables for mass balance\n",
    "bflow=tables['BOUNDARY_FLOW']\n",
    "sflow=tables['SOURCE_FLOW']\n",
    "srflow=tables['SOURCE_FLOW_RESERVOIR']\n",
    "trflow=tables['INPUT_TRANSFER_FLOW']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Builds a dictionary of {name: timeseries data} from a table that has atleast the following columns: NAME, FILE, PATH. \n",
    "\n",
    "The data is either \n",
    "* Timeseries data retrieved from a FILE ( DSS format) and PATH (DSS pathname)\n",
    "* Constant data when FILE is 'constant' & PATH is the value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_flows(table, base_dir):\n",
    "    '''\n",
    "    returns a dictionary of data indexed by NAME with SIGN from the FILE and PATH indicated in each row of the table\n",
    "    '''\n",
    "    data_dict = {}\n",
    "    for _,r in table.iterrows():\n",
    "        try:\n",
    "            logging.info(f'reading {base_dir}/{r.FILE}')\n",
    "            if r.FILE == 'constant':\n",
    "                rts, units, type = float(r.PATH), 'cfs', 'INST-VAL'\n",
    "            else:\n",
    "                rts, units, type = next(pyhecdss.get_ts(f'{base_dir}/{r.FILE}', r.PATH))\n",
    "            if units.casefold() != 'cfs'.casefold():\n",
    "                warnings.warn('%s::%s::%s -- Units expected are cfs, got : %s'%(r.NAME, r.FILE, r.PATH, units))\n",
    "            data_dict[r.NAME] = rts*float(r.SIGN)\n",
    "        except:\n",
    "            print('Error trying to retrieve %s from file %s & pathname %s'%(r.NAME, r.FILE, r.PATH))\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adds the time series (or constants)  in dictionary (see above)\n",
    "* checks for non-dataframes to add\n",
    "* converts period index to timestamp for add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum of all the time series\n",
    "# checks for non-dataframes to add\n",
    "# converts period index to timestamp for add\n",
    "def sum_dict(data_dict):\n",
    "    sum = 0.0\n",
    "    for k in data_dict:\n",
    "        data=data_dict[k]\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            if isinstance(data.index,pd.PeriodIndex):\n",
    "                #warnings.warn('Converting %s to timestamp'%k)\n",
    "                data.index=data.index.to_timestamp()\n",
    "            if data.index.freqstr != 'D':\n",
    "                data=data.resample('D').mean()\n",
    "            sum=sum+data.iloc[:,0]\n",
    "        else:\n",
    "            sum=sum+data\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the input and add up for total inflow\n",
    "Retreive the data into dictionary and also add up the flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bflows = read_flows(bflow, dsm2_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sflows = read_flows(sflow, dsm2_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srflows = read_flows(srflow, dsm2_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_bflow = sum_dict(bflows)\n",
    "sum_sflow = sum_dict(sflows)\n",
    "sum_srflow = sum_dict(srflows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Total Inflow as the sum of source/sink terms and boundary flows\n",
    "Also limit the timewindow to 1990-2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_inflow=sum_sflow+sum_bflow+sum_srflow\n",
    "total_inflow=total_inflow['SEP1990':'SEP2016']\n",
    "\n",
    "fig=total_inflow.plot(figsize=(15,5),title='Total Inflow')\n",
    "_=fig.set_ylabel('Flow (cfs)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the output file for outflow\n",
    "The outflow from DSM2 for the Delta has to go through channel 441. This flow is heavily tidal and the code below retrieves this from the model output file (HDF5 format) and tidally filters it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydsm.hydroh5\n",
    "hydro=pydsm.hydroh5.HydroH5(f'{dsm2_dir}/output/hist_v2022_01.h5')\n",
    "mtz_outflow=hydro.get_channel_flow('441','downstream')\n",
    "#flow4up=hydro.get_channel_flow('4','upstream')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out the tidal signal using cosine lanczos (preferred) or godin filter\n",
    "Also resample to daily flow (period average to daily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vtools.functions.filter import cosine_lanczos, godin\n",
    "fmtz=cosine_lanczos(mtz_outflow,cutoff_period='40h')\n",
    "#fmtz=godin(mtz_outflow)\n",
    "fdmtz=fmtz.resample('D').mean()\n",
    "ax1=fdmtz.plot(figsize=(15,5),title='Flow Past Martinez (Tidally filtered, daily average)')\n",
    "total_outflow=fdmtz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_inflow.hvplot(label='Total Inflow')*total_outflow.hvplot(label='Total Outflow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_inflow.resample('M').mean().hvplot(label='Total Inflow')*total_outflow.resample('M').mean().hvplot(label='Total Outflow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(total_outflow.iloc[:,0]-total_inflow).resample('M').mean().hvplot.area(label='Mass Balance').opts(xrotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dev_pydelmod]",
   "language": "python",
   "name": "conda-env-dev_pydelmod-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
