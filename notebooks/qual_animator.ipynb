{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydsm\n",
    "from pydsm import hydroh5\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shapely\n",
    "import geopandas as gpd\n",
    "import hvplot.pandas\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "import geoviews as gv\n",
    "hv.extension('bokeh')\n",
    "import panel as pn\n",
    "pn.extension()\n",
    "import colorcet as cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Holoviews version: ',hv.__version__)\n",
    "print('Geopandas version: ',gpd.__version__)\n",
    "print('Shapely version: ',shapely.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file='../tests/data/historical_v82_ec.h5'\n",
    "#file='d:/delta/DSM2v821/study_templates/historical/output/hist_v821_EC.h5'\n",
    "file='D:/dev/pydsm/tests/data/gtm_sample_output/historical_gtm.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df(file, offset=0, chunk_size=5000, constituent_id=0):\n",
    "    qh5=h5py.File(file,'r')\n",
    "    #qh5.visit(lambda name: print(name))\n",
    "    tcnames=qh5.get('output/constituent_names')\n",
    "    df_constituent_names=pd.DataFrame(tcnames)\n",
    "    df_constituent_names[constituent_id]=df_constituent_names[constituent_id].str.decode('utf-8')\n",
    "    df_constituent_names[constituent_id].values\n",
    "    #df_constituent_names[0][0].decode('UTF-8')\n",
    "    tsdata=qh5.get('output/channel concentration')\n",
    "    ttsdata=tsdata[offset:(offset+chunk_size),constituent_id,:,:]\n",
    "    attrs={k: tsdata.attrs[k] for k in tsdata.attrs.keys()}\n",
    "    #ttsdata.shape\n",
    "    #dfts=pd.DataFrame(data=ttsdata[])\n",
    "    #ttsdata.mean(axis=2).shape\n",
    "    data_len=ttsdata.shape[0]\n",
    "    nchans=ttsdata.shape[1]\n",
    "    nloc=ttsdata.shape[2]\n",
    "    mi=pd.MultiIndex.from_product([chan_index,['u','d']],names=['channel_number','u/d'])\n",
    "    start_time=pd.to_datetime(attrs['start_time'][0].decode('UTF-8'))\n",
    "    time_interval=pd.to_timedelta(attrs['interval'][0].decode('UTF-8'))\n",
    "    time_index=pd.date_range(start=start_time,periods=ttsdata.shape[0],freq=time_interval)\n",
    "    #index=start_time+np.arange(0,ttsdata.shape[0])*time_intervals\n",
    "    #print(index+np.arange(0,ttsdata.shape[0])*'H')\n",
    "    print(start_time)\n",
    "    ttsdf=pd.DataFrame(ttsdata.reshape(data_len,nchans*nloc),index=time_index,columns=mi)\n",
    "    return ttsdata,ttsdf,attrs,start_time,time_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_numbers(file):\n",
    "    qh5=h5py.File(file,'r')\n",
    "    return pd.DataFrame(qh5.get('output/channel_number'))[0].values\n",
    "chan_index=get_channel_numbers(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttsdata,ttsdf,attrs,start_time,time_interval=load_df(file,chunk_size=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def godin_filter_array(data):\n",
    "    '''godin filter the channel data for loaded time'''\n",
    "    from vtools.functions import filter\n",
    "    godin_fir=filter.generate_godin_fir(attrs['interval'][0].decode('UTF-8').replace('min','T'))\n",
    "    for outer in range(data.shape[2]):\n",
    "        for inner in range(data.shape[1]):\n",
    "            data[:,inner,outer]=np.convolve(data[:,inner, outer],godin_fir,mode='same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttsdatag=godin_filter_array(ttsdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_len=ttsdata.shape[0]\n",
    "nchans=ttsdata.shape[1]\n",
    "nloc=ttsdata.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_len,nchans,nloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttsdf_d=ttsdf.resample('D').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(ti=0):\n",
    "    return pd.DataFrame(ttsdf.iloc[ti].values.reshape(nchans,nloc).mean(axis=1),chan_index,columns=['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsm2_chans=gpd.read_file('../pydsm/maps/v8.2/DSM2_Flowline_Segments.shp').to_crs(epsg=3857)\n",
    "#dsm2_chans.geometry=dsm2_chans.geometry.simplify(tolerance=150)\n",
    "dsm2_chans.geometry=dsm2_chans.geometry.buffer(250,cap_style=1, join_style=1)\n",
    "#dsm2_chans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=get_data(0)\n",
    "dsm2_chans_m=dsm2_chans.merge(df,left_on='channel_nu',right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map=hv.element.tiles.CartoLight().opts(width=800,height=600,alpha=0.5)\n",
    "df=get_data(0)\n",
    "cur_time = start_time+pd.to_timedelta(attrs['interval'][0].decode('UTF-8'))# ti*pd.to_timedelta('1D')#\n",
    "tlabel = cur_time.strftime('%Y-%m-%d %H:%M')\n",
    "dsm2_chans_m=dsm2_chans.merge(df,left_on='channel_nu',right_index=True)\n",
    "chans_plot=dsm2_chans_m.hvplot(c='data',line_alpha=0, alpha=0.95, cmap='rainbow')\n",
    "chans_plot=chans_plot.redim.range(data=(100,1000)).opts(framewise=False)\n",
    "view=(map*chans_plot).opts(title='Time: %s'%tlabel,framewise=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from bokeh.io import push_notebook, show, output_notebook\n",
    "rendered_view=hv.render(view)\n",
    "pr=rendered_view.renderers[1]\n",
    "target = show(rendered_view, notebook_handle=True)\n",
    "def update_view(i=0):\n",
    "    df=get_data(i)\n",
    "    cur_time = start_time+i*pd.to_timedelta(attrs['interval'][0].decode('UTF-8'))# ti*pd.to_timedelta('1D')#\n",
    "    tlabel = cur_time.strftime('%Y-%m-%d %H:%M')\n",
    "    rendered_view.title.text=tlabel\n",
    "    dsm2_chans_mi=dsm2_chans.merge(df,left_on='channel_nu',right_index=True)\n",
    "    pr.data_source.data['color']=dsm2_chans_mi.data.values\n",
    "    pr.data_source.data['data']=dsm2_chans_mi.data.values\n",
    "    push_notebook(handle=target)\n",
    "import panel as pn\n",
    "pn.extension()\n",
    "pn.interact(update_view,i=(0,50000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "#from bokeh.io import push_notebook, show, output_notebook\n",
    "#rendered_view=hv.render(view)\n",
    "#pr=rendered_view.renderers[1]\n",
    "#target = show(rendered_view, notebook_handle=True)\n",
    "map=hv.element.tiles.CartoLight().opts(width=800,height=600,alpha=0.5)\n",
    "def update_view(i=0):\n",
    "    df=get_data(i)\n",
    "    cur_time = start_time+i*pd.to_timedelta(attrs['interval'][0].decode('UTF-8'))# ti*pd.to_timedelta('1D')#\n",
    "    tlabel = cur_time.strftime('%Y-%m-%d %H:%M')\n",
    "    rendered_view.title.text=tlabel\n",
    "    dsm2_chans_mi=dsm2_chans.merge(df,left_on='channel_nu',right_index=True)\n",
    "df=get_data(0)\n",
    "cur_time = start_time+pd.to_timedelta(attrs['interval'][0].decode('UTF-8'))# ti*pd.to_timedelta('1D')#\n",
    "tlabel = cur_time.strftime('%Y-%m-%d %H:%M')\n",
    "dsm2_chans_m=dsm2_chans.merge(df,left_on='channel_nu',right_index=True)\n",
    "chans_plot=dsm2_chans_m.hvplot(c='data',line_alpha=0, alpha=0.95, cmap='rainbow')\n",
    "chans_plot=chans_plot.redim.range(data=(100,1000)).opts(framewise=False)\n",
    "view=(map*chans_plot).opts(title='Time: %s'%tlabel,framewise=False)\n",
    "#import panel as pn\n",
    "#pn.extension()\n",
    "#pn.interact(update_view,i=(0,50000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datashader as ds, pandas as pd\n",
    "import datashader.transfer_functions as tf\n",
    "from holoviews.operation.datashader import datashade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import panel as pn\n",
    "pn.extension()\n",
    "map=hv.element.tiles.CartoLight().opts(width=800,height=600,alpha=0.5)\n",
    "def channel_map(ti):\n",
    "    df=get_data(ti)\n",
    "    cur_time = start_time+ti*pd.to_timedelta('1D')#pd.to_timedelta(attrs['interval'][0].decode('UTF-8'))\n",
    "    tlabel = cur_time.strftime('%Y-%m-%d %H:%M')\n",
    "    dsm2_chans_m2=dsm2_chans.merge(df,left_on='channel_nu',right_index=True)\n",
    "    dsm2_chans_m['data']=dsm2_chans_m2['data']\n",
    "    chans_plot=hv.Polygons(dsm2_chans_m,vdims=['data']).opts(line_alpha=0, alpha=0.95, cmap=cc.rainbow)\n",
    "    chans_plot=chans_plot.redim.range(data=(100,1000))#.opts(framewise=False)\n",
    "    ov=map*chans_plot.opts(title='Time: %s'%tlabel)#,framewise=False)\n",
    "    return ov\n",
    "dmap=hv.DynamicMap(channel_map,kdims=['ti'])\n",
    "anim_pane=dmap.redim.range(ti=(0,len(ttsdf_d)-1)).opts(framewise=False)\n",
    "p=pn.panel(anim_pane)\n",
    "titlePane=pn.pane.Markdown(''' # %s Animation (Tidally Filtered)'''%'EC')\n",
    "anim_panel=pn.Column(pn.Row(titlePane,*p[1]),p[0])\n",
    "pn.ipywidget(anim_panel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw=dict(ti=(0,len(ttsdf_d)))\n",
    "pn.interact(channel_map,**kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "date_slider = pn.widgets.DateSlider(name='Date Slider', start=dt.datetime(2019, 1, 1), end=dt.datetime(2019, 6, 1), value=dt.datetime(2019, 2, 8))\n",
    "date_slider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_dist_for_ec(df1, ecx2=2700):\n",
    "    '''\n",
    "    Finds channels that containt the ecx2 value and then linearly interpolates to find normalized distance (0 -> 1)\n",
    "    returns a data frame of norm_dist dataframe\n",
    "    '''\n",
    "    dfu=df1[:,'u']\n",
    "    dfd=df1[:,'d']\n",
    "    cond1=(dfu < ecx2) & (dfd > ecx2)\n",
    "    cond2=(dfu > ecx2) & (dfd < ecx2)\n",
    "    cond_between= cond1 | cond2\n",
    "    #dfu[cond_between]\n",
    "    #dfd[cond_between]\n",
    "    return abs((ecx2-dfd[cond_between])/(ecx2-dfu[cond_between]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "from shapely.geometry import LineString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsm2_chanso=gpd.read_file('maps/v8.2/DSM2_Flowline_Segments.shp').to_crs(epsg=3857)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x2_map(ti,ecx2=2700):\n",
    "    norm_dist=norm_dist_for_ec(ttsdf_d.iloc[ti],ecx2)\n",
    "    dsm2_x2=dsm2_chans.join(norm_dist,on='channel_nu',how='right')\n",
    "    #dsm2_x2\n",
    "    x2_line_df=dsm2_x2.geometry.interpolate(dsm2_x2[dsm2_x2.columns[-1]])\n",
    "    xl=x2_line_df.values.x\n",
    "    yl=x2_line_df.values.y\n",
    "    f=interp1d(x2_line_df.values.x, x2_line_df.values.y)\n",
    "    x2_line=LineString(x2_line_df.values)\n",
    "    return x2_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmap[10]*hv.Path(x2_map(10)).opts(line_width=5, line_color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmap[120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dev_pydsm]",
   "language": "python",
   "name": "conda-env-dev_pydsm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "d893f331d7126c42ce5b27ef0f7a3dcadbe9d48ac6c9a8d9f3ee14a6e5bdfa82"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
