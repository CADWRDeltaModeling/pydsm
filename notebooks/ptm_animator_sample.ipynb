{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PTM Animator Sample\n",
    "\n",
    "This notebook shows how a PTM animation can be done with numpy, pandas, geopandas, shapely and holoviews. This is shared to be a useful tool while a more generalized tool is being built.\n",
    "\n",
    "**This sample will note be developed further and many of the functions here will be moved to pydsm modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import datashader.geo\n",
    "import hvplot.pandas\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "hv.extension('bokeh')\n",
    "import geopandas\n",
    "import shapely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reads ptm animation binary file. needs swap to small endians\n",
    "def load_anim_data(ptm_file):\n",
    "    ptm_meta=np.core.records.fromfile(ptm_file,dtype=[('x','>h'), ('model_date','a9'), ('model_time','>h'), ('nparticles','>h')], shape=1)\n",
    "    nparticles=ptm_meta.nparticles[0]\n",
    "    ptm_data=np.core.records.fromfile(ptm_file,dtype=[('x','>h'), ('model_date','a9'), ('model_time','>h'), ('nparticles','>h'),('positions','(%d,6)>h'%nparticles)])\n",
    "    ptm_data=ptm_data.byteswap().newbyteorder() # Needed for converting big endianess to small endianess\n",
    "    return ptm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydsm\n",
    "from pydsm import ptm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptm_file='D:/delta/dsm2_v8.2.0b1/studies/historical/output/anim_db.bin'\n",
    "ptm_data=ptm.load_anim_data(ptm_file)\n",
    "print('PTM Animation file has %d records'%len(ptm_data))\n",
    "print('Animation starts at %s %04d'%(ptm_data[0].model_date.decode(\"utf-8\"),ptm_data[0].model_time))\n",
    "print('Animation ends at %s %04d'%(ptm_data[-1].model_date.decode(\"utf-8\"),ptm_data[-1].model_time))\n",
    "print('There are %d particles in this animation'%ptm_data[0].nparticles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfall=ptm.create_frame_for_anim_data(ptm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydsm.hydroh5\n",
    "hydrofile='D:/delta/dsm2_v8.2.0b1/studies/historical/output/historical_v82.h5'\n",
    "hydro=pydsm.hydroh5.HydroH5(hydrofile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chan_int2ext=pd.DataFrame(hydro.channel_index2number.items(),columns=['internal','external'],dtype=np.int32)\n",
    "chan_int2ext=chan_int2ext.assign(internal=chan_int2ext.internal+1)\n",
    "chan_int2ext.index=chan_int2ext.internal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfallj=dfall.join(chan_int2ext,on='cid')\n",
    "dfallj=dfallj.fillna({'internal':-1,'external':-1})\n",
    "dfallj=dfallj.astype({'internal':np.int32,'external':np.int32})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dsm2_chans=geopandas.read_file('maps/v8.2/DSM2_Channels.shp').to_crs(epsg=3857)\n",
    "dsm2_chans=geopandas.read_file('D:/delta/maps/v8.2/DSM2_Flowline_Segments.shp').to_crs(epsg=3857)\n",
    "dsm2_chan_geom_map={}\n",
    "# map from index+1 (numbers 1--> higher to )\n",
    "for r in dsm2_chans.iterrows():\n",
    "    chan=r[1]\n",
    "    chan_index = hydro.channel_number2index[str(chan.channel_nu)]\n",
    "    dsm2_chan_geom_map[chan_index+1] = chan.geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dsm2_chans.index=dsm2_chans.ChannelNum\n",
    "#dfallj=dfallj.join(dsm2_chans['geometry'],on='external')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfallj[dfallj.id==1].external.hvplot()*dfallj[dfallj.id==10].external.hvplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multindex_iloc(df, index):\n",
    "    label = df.index.levels[0][index]\n",
    "    return label,df.iloc[df.index.get_loc(label)]\n",
    "def get_chan_geometry(channel_id):\n",
    "    return dsm2_chan_geom_map[channel_id]\n",
    "def interpolate_positions(dfn):\n",
    "    vals=np.empty(len(dfn),dtype='object')\n",
    "    i=0\n",
    "    for r in dfn.iterrows():\n",
    "        try:\n",
    "            if r[1].cid > 0:\n",
    "                geom=get_chan_geometry(r[1].cid)\n",
    "                val=geom.interpolate(1.0-r[1].x/100.0,normalized=True)\n",
    "                vals[i]=val\n",
    "            i=i+1\n",
    "        except:\n",
    "            print('Exception for row: ',i, r)\n",
    "            raise\n",
    "    return vals\n",
    "def get_particle_geopositions(time_index, dfall):\n",
    "    dt,dfn = multindex_iloc(dfall,time_index) #\n",
    "    #dfn=dfn.droplevel(0) # drop level as time is the slice \n",
    "    dfn=dfall.loc[dt]\n",
    "    #dfn['geometry'] = interpolate_positions(dfn) # add new column to copy of full slice so warning is ok\n",
    "    dfn.assign(geometry=interpolate_positions(dfn))\n",
    "    dfp=dfn[dfn.cid>0]\n",
    "    gdf_merc=geopandas.GeoDataFrame(dfp,geometry='geometry',crs='EPSG:3857')\n",
    "    #gdf_merc=gdf.to_crs(epsg=3857)\n",
    "    x= np.fromiter((p.x for p in gdf_merc.geometry.values), dtype=np.float32)\n",
    "    y = np.fromiter((p.y for p in gdf_merc.geometry.values), dtype=np.float32)\n",
    "    dfp_xy = dfp.join([pd.DataFrame({'easting':x}), pd.DataFrame({'northing':y})])\n",
    "    return dfp_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cache_calcs(df):\n",
    "    apos=interpolate_positions(df)\n",
    "    #df_xy=df.assign('geometry',apos) # do we need the geometry column ?\n",
    "    x=np.fromiter( (p.x if p else None for p in apos), dtype=np.float32)\n",
    "    y=np.fromiter( (p.y if p else None for p in apos), dtype=np.float32)\n",
    "    df_xy=df.assign(easting=x, northing=y)\n",
    "    #save dfall_xy to cached parquet format or feather format\n",
    "    return df_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment below to recalculate cached\n",
    "try:\n",
    "    dfall_xy = pd.read_pickle(ptm_file+'.pickle') # executed in 195ms\n",
    "    #pd.read_parquet(ptm_file+'.parquet') # executed in 870 ms\n",
    "    #pd.read_csv(ptm_file+'.csv') # executed in 4.30s,\n",
    "except: \n",
    "    print('Failed to load cached calculated particle positions. Recalculating ...')\n",
    "    dfall_xy=cache_calcs(dfall)\n",
    "    dfall_xy.to_pickle(ptm_file+'.pickle') # executed in 469ms\n",
    "#dfall_xy.to_feather(ptm_file+'.feather') # failed to serialize multiindex\n",
    "#dfall_xy.to_parquet(ptm_file+'.parquet') # executed in 2.01s, 30 MB\n",
    "#dfall_xy.to_csv(ptm_file+'.csv') # executed in 29.6s, 348 MB\n",
    "#dfall_xy.to_pickle(ptm_file+'.pickle') # executed in 469ms, 138 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfall_xy.loc['2016-07-05']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tlabel=dfall_xy.index.levels[0][500]\n",
    "#print(tlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfp_xy=dfall_xy.loc[tlabel]\n",
    "#dfp_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import panel as pn\n",
    "# Tiles always in pseudo mercator epsg=3857\n",
    "b=dsm2_chans.to_crs(epsg=3857).geometry.bounds\n",
    "extents=(b.minx.min(),b.miny.min(),b.maxx.max(),b.maxy.max())\n",
    "map=hv.element.tiles.OSM().opts(width=800,height=600)\n",
    "map.extents=extents\n",
    "#display(map)\n",
    "def particle_map(ti):\n",
    "    tlabel=dfall_xy.index.levels[0][ti]\n",
    "    dfp_xy=dfall_xy.loc[tlabel] \n",
    "    ov=map*dfp_xy.hvplot.points(x='easting',y='northing',hover_cols=['id','cid']).opts(title=\"Time: %s\"%tlabel,framewise=False)\n",
    "    return ov\n",
    "dmap=hv.DynamicMap(particle_map,kdims=['ti'])\n",
    "time_index=dfall_xy.index.levels[0]\n",
    "anim_pane=dmap.redim.range(ti=(0,len(ptm_data)-1)).opts(framewise=True)\n",
    "p=pn.panel(anim_pane)\n",
    "titlePane=pn.pane.Markdown(''' # Particle Animation''')\n",
    "anim_panel=pn.Column(pn.Row(titlePane,*p[1]),p[0])\n",
    "anim_panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dsm2_chans.hvplot.line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#anim_pane.select(ti=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pl1=dfall_xy[dfall_xy.id==373].cid.hvplot()\n",
    "#pl2=dfall_xy[dfall_xy.id==151].cid.hvplot()\n",
    "#pl1*pl2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#anim_pane.select(ti=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from holoviews.streams import Selection1D\n",
    "#sel = Selection1D(source=anim_pane[0].Points.I)\n",
    "\n",
    "\n",
    "#print(anim_pane)\n",
    "\n",
    "#hv.DynamicMap(lambda index: dfall_xy[dfall_xy.index==id].hvplot(), streams=[sel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dev_pydsm]",
   "language": "python",
   "name": "conda-env-dev_pydsm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
