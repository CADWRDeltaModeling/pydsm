{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is to read DSM2 hdf5 output directly and load it into pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pydsm\n",
    "from pydsm.io import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "Reading in the hdf5 file and table output/channel avg concentration into a pandas frame. \n",
    "This is a multi-dimensional table so hierarchical indices are needed to accomodate it. \n",
    "The attributes for the table contain the start time and time interval and those are used for indexing the first dimension as a datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_table_as_array(file_path, table_path, dtype=str):\n",
    "    '''\n",
    "    reads table from h5 file_path from the table_path and returns array of dtype\n",
    "    '''\n",
    "    with h5py.File(file_path,'r') as f:\n",
    "        return np.array(f[table_path]).astype(dtype)\n",
    "def read_dsm2_table(file_path, table_path, column_values, column_names, start_time_key='start_time', interval_key='interval'):\n",
    "    '''\n",
    "    file_path: Name of h5 file (full path or relative path)\n",
    "    table_path: Path within the h5 file to the values table e.g. /output/channel_concentrations\n",
    "    column_values: Values used for the 2nd and 3rd dimension of table. \n",
    "        For DSM2 the 2nd dimension is the variable dimension (flow, stage, constituent)\n",
    "                 the 3rd dimension is the location dimension (channel, reservoir)\n",
    "                 Time is always assumed to be the first dimension in the table\n",
    "    column_names: Names for the 2nd and 3rd dimensions\n",
    "    '''\n",
    "    with h5py.File(file_path,'r') as f:\n",
    "        v=f[table_path]\n",
    "        a=v.attrs\n",
    "        start_time=str(a[start_time_key].astype(str)[0])\n",
    "        interval=str(a[interval_key].astype(str)[0])\n",
    "        vals=np.array(v)\n",
    "    c1=column_values[0]\n",
    "    c2=column_values[1]\n",
    "    x1=c1.repeat(c2.size)\n",
    "    x2=c2.repeat(c1.size)\n",
    "    vi=pd.MultiIndex.from_arrays([x1,x2],names=tuple(column_names))\n",
    "    vti=pd.DatetimeIndex(data=pd.date_range(start=start_time,freq=interval,periods=vals.shape[0])\n",
    "            ,name=\"Time\")\n",
    "    return pd.DataFrame(data=vals.reshape(vals.shape[0],vals.shape[1]*vals.shape[2]),index=vti,columns=vi)\n",
    "def generate_godin_fir(timeinterval='1hour'):\n",
    "    '''\n",
    "    generate godin filter impulse response for given timeinterval\n",
    "    '''\n",
    "    mins=pd.Timedelta(timeinterval).seconds/60 # FIXME: needs mins_in_interval function\n",
    "    wts24=np.zeros(round(24*60/mins))\n",
    "    wts24[:]=1/wts24.size\n",
    "    tidal_period=round(24.75*60/mins)\n",
    "    if tidal_period%2==0: tidal_period=tidal_period+1\n",
    "    wts25=np.zeros(tidal_period)\n",
    "    wts25[:]=1.0/wts25.size\n",
    "    return np.convolve(wts25,np.convolve(wts24,wts24))\n",
    "def godin_filter(df,timeinterval='15min'):\n",
    "    '''\n",
    "    return godin filtered values for data frame values\n",
    "    '''\n",
    "    godin_ir=generate_godin_fir(timeinterval)\n",
    "    dfg=pd.DataFrame(np.convolve(df.values,godin_ir,mode='same'))\n",
    "    dfg.index=df.index\n",
    "    return dfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='../tests/historical_v82_ec.h5'\n",
    "na1=read_table_as_array(filename,'output/constituent_names')\n",
    "na2=read_table_as_array(filename, 'output/channel_number',dtype=int)\n",
    "#print(na1,na2)\n",
    "df=read_dsm2_table(filename,'output/channel avg concentration',[na1,na2],['constituent','channel'])\n",
    "#display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('dsm2-flowpolygons.geojson') as f: dsm2_grid=json.load(f)\n",
    "for g in dsm2_grid['features']: g['id']=int(g['properties']['channel_nu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyleaflet\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "from branca.colormap import linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map \n",
    "<font color=red>Warning: Geojson with polygons for channels is needed!</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_time_steps=len(df.index)\n",
    "constituent_names=na1\n",
    "#\n",
    "def extract_constituent_as_dict(df, timestep=0,constituent_name='ec'):\n",
    "    tblx=df.iloc[timestep][constituent_name,slice(None)]\n",
    "    return tblx.to_dict()\n",
    "tbl0=extract_constituent_as_dict(df,100,'ec')\n",
    "#\n",
    "import matplotlib\n",
    "import matplotlib.ticker\n",
    "def make_nice_rounded_range(min,max,steps=10):\n",
    "    l = matplotlib.ticker.AutoLocator()\n",
    "    l.create_dummy_axis()\n",
    "    x=l.tick_values(min,max)\n",
    "    return x[0],x[-1]\n",
    "#\n",
    "layer = ipyleaflet.Choropleth(\n",
    "    geo_data=dsm2_grid,\n",
    "    choro_data=tbl0,\n",
    "    value_min=100,\n",
    "    value_max=25000,\n",
    "    colormap=linear.Spectral_11, #linear.YlOrRd_04,\n",
    "    style={'fillOpacity': 1.0})\n",
    "#\n",
    "def update_legend():\n",
    "    # add legend\n",
    "    v=layer.choro_data.values()\n",
    "    r=make_nice_rounded_range(min(v),max(v))\n",
    "    legend=linear.RdBu_11.scale(r[0],r[1])\n",
    "    layer.colormap=legend\n",
    "    out.clear_output()\n",
    "    with out:\n",
    "        display(legend)\n",
    "\n",
    "def handle_slider_change(change):\n",
    "    print(change.new)\n",
    "    layer.choro_data=extract_constituent_as_dict(df,change.new, constituent_selector.value)\n",
    "    \n",
    "def handle_dropdown_change(change):\n",
    "    layer.choro_data=extract_constituent_as_dict(df,slider.value, constituent_selector.value)\n",
    "    update_legend()\n",
    "\n",
    "#\n",
    "m = ipyleaflet.Map(center = (38,-121), zoom = 11)\n",
    "m.add_layer(layer)\n",
    "m.add_control(ipyleaflet.FullScreenControl())\n",
    "#add slider control\n",
    "slider = widgets.IntSlider(min=0, max=max_time_steps, continuous_update=False)\n",
    "slider.value = 0\n",
    "slider.observe(handle_slider_change, names='value')\n",
    "play = widgets.Play(\n",
    "    value=0,\n",
    "    interval=5000,\n",
    "    min=0,\n",
    "    max=max_time_steps,\n",
    "    step=1,\n",
    "    description=\"Press play\",\n",
    "    disabled=False\n",
    ")\n",
    "widgets.jslink((play, 'value'), (slider, 'value'))\n",
    "constituents=constituent_names\n",
    "constituent_selector=widgets.Dropdown(\n",
    "    options=constituents,\n",
    "    value='ec',\n",
    "    description='Constituent:',\n",
    "    disabled=False,\n",
    ")\n",
    "constituent_selector.observe(handle_dropdown_change, names='value')\n",
    "#\n",
    "#\n",
    "control_widget=widgets.HBox([play, slider])\n",
    "control_widget=widgets.VBox([constituent_selector,control_widget])\n",
    "widget_control = ipyleaflet.WidgetControl(widget=control_widget, position='bottomright')\n",
    "m.add_control(widget_control)\n",
    "out = widgets.Output(layout={'border': '1px solid black'})\n",
    "update_legend()\n",
    "widget_control2 = ipyleaflet.WidgetControl(widget=out, position='topright')\n",
    "m.add_control(widget_control2)\n",
    "display(m)\n",
    "#\n",
    "#\n",
    "#%matplotlib notebook\n",
    "widget_output = widgets.Output(layout={'border': '1px solid black'})\n",
    "def handle_click(**kwargs):\n",
    "    if not 'id' in kwargs: return\n",
    "    widget_output.clear_output(wait=True)\n",
    "    cell_id=kwargs['id']\n",
    "    with widget_output:\n",
    "        p=kwargs['properties']\n",
    "        for k in p:\n",
    "            if k == 'id' or k == 'style': continue\n",
    "            display(str(k)+' : '+str(p[k]))\n",
    "        fig1, axes1 = plt.subplots()\n",
    "        axes1.set_title(str(constituent_selector.value) + ' for ' + str(cell_id))\n",
    "        axes1.set_ylabel(str(constituent_selector.value))\n",
    "        #line1=axes1.axvline(x=slider.value,color='grey')\n",
    "        #slider.observe(handle_line_)\n",
    "        godin_filter(df.loc[:,(constituent_selector.value, cell_id)],'1hour').plot(kind='line',ax = axes1)\n",
    "        plt.show(fig1)\n",
    "layer.on_click(handle_click)\n",
    "display(widget_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100): extract_constituent_as_dict(df,i, 'ec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtz_to_chipps=[441,440,452,438,443,437]\n",
    "#ecdf['ec'][mtz_to_chipps]\n",
    "mtzec=df['ec'][441]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtzecg=godin_filter(mtzec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "axes1=mtzec.plot()\n",
    "mtzecg.plot(ax=axes1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtzec_daily=mtzec.resample('D').mean()\n",
    "mtzecg_daily=mtzecg.resample('D').mean()\n",
    "display(len(mtzecg_daily),len(mtzec_daily))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('dev_pydsm': conda)",
   "language": "python",
   "name": "python37664bitdevpydsmcondab1c3bd5d933c4dabb1711f6f5582ad21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
