{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to split hydro h5 file by timewindow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hfile='../tests/data/historical_v82.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf=h5py.File(hfile,'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start with the root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[g for g in hf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show next level down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[g for g in hf['hydro']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_children(hf,path):\n",
    "    return [g for g in hf[path]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Children of data \n",
    "This contains the time indexed data tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tables=get_children(hf,'/hydro/data')\n",
    "print(data_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Children of geometry\n",
    "These are the geometry tables for hydro. Typically can be represented by 2D tables and is the internal information in hydro and should be used to interpret the tables in /hydro/data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry_tables=get_children(hf,'/hydro/geometry')\n",
    "print(geometry_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Children of input\n",
    "These are the tables of hydro input. This is how hydro views the input provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tables=get_children(hf,'/hydro/input')\n",
    "print(input_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slicing for a time window and saving to a new hydro file\n",
    "\n",
    "* The tables under /hydro/data should be sliced for this time window. This should be straightforward once the index corresponding to the time window is calculated, then the table sliced and the slice written to the new file\n",
    "* The tables under /hydro/geometry should not be effected by the time window slicing so should just be copied over to the new file.\n",
    "* The tables under /hydro/input has the model start time and end time. Those could be argued to be sliced as well. However for QUAL and PTM (the programs using this information), they usually do not look at the start/end time information from the tidefile and so it is optional to change this information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=hf[f'/hydro/data/{data_tables[0]}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_start_time(tbl):\n",
    "    return tbl.attrs['start_time'][0].decode('utf-8')\n",
    "def get_time_interval(tbl):\n",
    "    return tbl.attrs['interval'][0].decode('utf-8')\n",
    "def get_slice_indices(tbl,stime,etime):\n",
    "    dindex=pd.date_range(start=get_start_time(tbl),freq=get_time_interval(tbl),periods=tbl.shape[0])\n",
    "    dfindex=pd.DataFrame(np.arange(tbl.shape[0]),index=dindex)\n",
    "    return tuple(dfindex[stime:etime].iloc[[0,-1]][0].values)\n",
    "def slice_table(tbl,stime,etime):\n",
    "    bi,ei=get_slice_indices(tbl,stime,etime)\n",
    "    return tbl[slice(bi,ei)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile='%s_sliced.h5'%hfile.split('.h5')[0]\n",
    "print(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_attrs_table(ntbl,tbl):\n",
    "    for a in tbl.attrs:\n",
    "        ntbl.attrs[a]=tbl.attrs[a]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mins_since_origin(dstr,origin_date='1899-12-31'):\n",
    "    '''\n",
    "    origin date default is HEC convention. \n",
    "    '''\n",
    "    delt=pd.to_datetime(dstr)-pd.to_datetime(origin_date)\n",
    "    return delt.total_seconds()/60.\n",
    "\n",
    "x=mins_since_origin('1990-01-02','1899-12-31')\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stime='1990-01-10'\n",
    "etime='1990-01-15'\n",
    "with h5py.File(outfile, \"w\") as nhf:\n",
    "    for tname in data_tables:\n",
    "        tpath='/hydro/data/%s'%tname\n",
    "        tbl=hf[tpath]\n",
    "        nhf[tpath]=slice_table(tbl,stime,etime)\n",
    "        ntbl=nhf[tpath]\n",
    "        copy_attrs_table(ntbl,tbl)\n",
    "        ntbl.attrs['start_time']=bytes(str(pd.to_datetime(stime)),'utf-8')\n",
    "    for tname in geometry_tables:\n",
    "        tpath='/hydro/geometry/%s'%tname\n",
    "        tbl=hf[tpath]\n",
    "        nhf[tpath]=hf[tpath][:]\n",
    "        ntbl=nhf[tpath]\n",
    "        copy_attrs_table(ntbl,tbl)\n",
    "    for tname in input_tables:\n",
    "        tpath='/hydro/input/%s'%tname\n",
    "        tbl=hf[tpath]\n",
    "        nhf[tpath]=hf[tpath][:]\n",
    "        ntbl=nhf[tpath]\n",
    "        copy_attrs_table(ntbl,tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf['hydro'].attrs['Start time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf['hydro'].attrs['Start time string']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime('10JAN1990').strftime('%d%b%Y %H%M').upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dev_pydsm]",
   "language": "python",
   "name": "conda-env-dev_pydsm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
